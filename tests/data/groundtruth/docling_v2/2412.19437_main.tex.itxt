item-0 at level 0: unspecified: group _root_
  item-1 at level 1: text: UTF8gbsn
  item-2 at level 1: section: group figure
    item-3 at level 2: picture
      item-3 at level 3: caption: Image: figures/dsv3_performance.pdf
    item-4 at level 2: text: Benchmark performance of DeepSeek-V3 and its counterparts.
  item-5 at level 1: caption: Image: figures/dsv3_performance.pdf
  item-6 at level 1: text: 0.9
  item-7 at level 1: section_header: Introduction
  item-8 at level 1: paragraph: In recent years, Large Language Models
  item-9 at level 1: text: (LLMs) have been undergoing rapi ... hich 37B are activated for each token.
  item-10 at level 1: paragraph: With a forward-looking perspecti ... .
Therefore, in terms of architecture,
  item-11 at level 1: text: DeepSeek-V3 still adopts Multi-h ...  performance on evaluation benchmarks.
  item-12 at level 1: paragraph: In order to achieve efficient tr ... mising solution for efficient training
  item-13 at level 1: text: [bf16train, fp16train, fp8lm, ll ... , we achieve high training efficiency.
  item-14 at level 1: paragraph: During pre-training, we train
  item-15 at level 1: text: DeepSeek-V3 on 14.8T high-qualit ...  model accuracy and generation length.
  item-16 at level 1: paragraph: We evaluate
  item-17 at level 1: text: DeepSeek-V3 on a comprehensive a ... of standard and open-ended benchmarks.
  item-18 at level 1: text: 6pt
  item-19 at level 1: table with [4x5]
  item-20 at level 1: text: Training costs of DeepSeek-V3, a ... ntal price of H800 is $2 per GPU hour.
  item-21 at level 1: paragraph: Lastly, we emphasize again the economical training costs of
  item-22 at level 1: text: DeepSeek-V3, summarized in Table ... on architectures, algorithms, or data.
  item-23 at level 1: paragraph: Our main contribution includes:
  item-24 at level 1: text: Architecture: Innovative Load Balancing Strategy and Training Objective
  item-25 at level 1: list: group list
    item-26 at level 2: list_item: On top of the efficient architec ... rises from encouraging load balancing.
    item-27 at level 2: list_item: We investigate a Multi-Token Pre ... e decoding for inference acceleration.
  item-28 at level 1: text: Pre-Training: Towards Ultimate Training Efficiency
  item-29 at level 1: list: group list
    item-30 at level 2: list_item: We design an FP8 mixed precision ... ing on an extremely large-scale model.
    item-31 at level 2: list_item: Through the co-design of algorit ... odel size without additional overhead.
    item-32 at level 2: list_item: At an economical cost of only 2. ... -training require only 0.1M GPU hours.
  item-33 at level 1: text: Post-Training: Knowledge Distillation from DeepSeek-R1
  item-34 at level 1: list: group list
    item-35 at level 2: list_item: We introduce an innovative metho ... utput style and length of DeepSeek-V3.
  item-36 at level 1: text: Summary of Core Evaluation Results
  item-37 at level 1: list: group list
    item-38 at level 2: list_item: Knowledge:
    (1) 
    On educa ... strength in Chinese factual knowledge.
    item-39 at level 2: list_item: Code, Math, and Reasoning: 
     ... s across diverse technical benchmarks.
  item-40 at level 1: text: In the remainder of this paper,  ... re research (Section[sec:conclusion]).
  item-41 at level 1: section_header: Architecture
  item-42 at level 1: paragraph: We first introduce the basic architecture of
  item-43 at level 1: text: DeepSeek-V3, featured by Multi-h ... to the settings of DeepSeek-V2[dsvii].
  item-44 at level 1: section: group figure
    item-45 at level 2: picture
      item-45 at level 3: caption: Image: figures/basic_arch.pdf
    item-46 at level 2: text: Illustration of the basic archit ... ent inference and economical training.
  item-47 at level 1: caption: Image: figures/basic_arch.pdf
  item-48 at level 1: section_header: Basic Architecture
  item-49 at level 1: paragraph: The basic architecture of
  item-50 at level 1: text: DeepSeek-V3 is still within the  ... f MLA and DeepSeekMoE in this section.
  item-51 at level 1: section_header: Multi-Head Latent Attention
  item-52 at level 1: paragraph: For attention,
  item-53 at level 1: text: DeepSeek-V3 adopts the MLA archi ... Key-Value (KV) cache during inference:
  item-54 at level 1: formula: \begin{align}
    \boxed{\color{ ... {UV} \mathbf{c}_{t}^{KV}, 
\end{align}
  item-55 at level 1: text: where $\mathbf{c}_{t}^{KV} \in \ ... lti-Head Attention (MHA)[transformer].
  item-56 at level 1: paragraph: For the attention queries, we al ... the activation memory during training:
  item-57 at level 1: formula: \begin{align}
    \mathbf{c}_{t} ... }; \mathbf{q}_{t, i}^{R}],
\end{align}
  item-58 at level 1: text: where $\mathbf{c}_{t}^{Q} \in \m ... the decoupled queries that carry RoPE.
  item-59 at level 1: paragraph: Ultimately, the attention queries (
  item-60 at level 1: text: $\mathbf{q}_{t, i}$), keys ($\ma ... nal attention output $\mathbf{u}_{t}$:
  item-61 at level 1: formula: \begin{align}
    \mathbf{o}_{t, ... ..;\mathbf{o}_{t, n_{h}}],
\end{align}
  item-62 at level 1: text: where $W^{O} \in \mathbb{R}^{d \ ... $denotes the output projection matrix.
  item-63 at level 1: section_header: DeepSeekMoE with Auxiliary-Loss-Free Load Balancing
  item-64 at level 1: text: Basic Architecture of DeepSeekMo ...  $\mathbf{h}_{t}^{\prime}$ as follows:
  item-65 at level 1: formula: \begin{align}
    \mathbf{h}_{t} ... T} \mathbf{e}_{i} \right),
\end{align}
  item-66 at level 1: text: where $N_{s}$ and $N_r$ denote t ... y scores to produce the gating values.
  item-67 at level 1: text: Auxiliary-Loss-Free Load Balanci ... {i,t}$ to determine the top-K routing:
  item-68 at level 1: formula: \begin{align}
    g^{\prime}_{i, ... therwise}.
    \end{cases}
\end{align}
  item-69 at level 1: text: Note that the bias term is only  ... balance through pure auxiliary losses.
  item-70 at level 1: text: Complementary Sequence-Wise Auxi ... plementary sequence-wise balance loss:
  item-71 at level 1: formula: \begin{align}
    \mathcal{L}_{\ ... =1}^{T}{s^{\prime}_{i,t}},
\end{align}
  item-72 at level 1: text: where the balance factor $\alpha ...  load on each sequence to be balanced.
  item-73 at level 1: text: Node-Limited Routing.
Like the d ... ull computation-communication overlap.
  item-74 at level 1: text: No Token-Dropping.
Due to the ef ... does not drop tokens during inference.
  item-75 at level 1: section: group figure
    item-76 at level 2: picture
      item-76 at level 3: caption: Image: figures/nextn.pdf
    item-77 at level 2: text: Illustration of our Multi-Token  ... rediction of each token at each depth.
  item-78 at level 1: caption: Image: figures/nextn.pdf
  item-79 at level 1: section_header: Multi-Token Prediction
  item-80 at level 1: paragraph: Inspired by
  item-81 at level 1: text: [meta_mtp], we investigate and s ... ur MTP implementation in this section.
  item-82 at level 1: text: MTP Modules.
To be specific, our ... bb{R}^{d}$ with the linear projection:
  item-83 at level 1: formula: \mathbf{h}_i^{\prime k} = M_k [\ ... MSNorm}(\operatorname{Emb}(t_{i+k}))],
  item-84 at level 1: text: where $[\cdot ; \cdot]$ denotes  ... he current depth $\mathbf{h}_{i}^{k}$:
  item-85 at level 1: formula: \mathbf{h}_{1:T-k}^{k} = \operat ... TRM}_k(\mathbf{h}_{1:T-k}^{\prime k}),
  item-86 at level 1: text: where $T$ represents the input s ... V}$, where $V$ is the vocabulary size:
  item-87 at level 1: formula: P_{i+k+1}^{k} = \operatorname{OutHead}(\mathbf{h}_{i}^{k}).
  item-88 at level 1: text: The output head $\operatorname{O ... as we utilize MTP to improve training.
  item-89 at level 1: text: MTP Training Objective.
For each ... y loss $\mathcal{L}_{\text{MTP}}^{k}$:
  item-90 at level 1: formula: \mathcal{L}_{\text{MTP}}^{k} = \ ... um_{i=2 + k}^{T + 1} \log P_i^k [t_i],
  item-91 at level 1: text: where $T$ denotes the input sequ ... al training objective for DeepSeek-V3:
  item-92 at level 1: formula: \mathcal{L}_{\text{MTP}} = \frac ... k=1}^{D} \mathcal{L}_{\text{MTP}}^{k}.
  item-93 at level 1: text: MTP in Inference.Our MTP strateg ... urther improve the generation latency.
  item-94 at level 1: section_header: Infrastructures
  item-95 at level 1: section_header: Compute Clusters
  item-96 at level 1: text: DeepSeek-V3 is trained on a clus ... utilized to facilitate communications.
  item-97 at level 1: section_header: Training Framework
  item-98 at level 1: paragraph: The training of
  item-99 at level 1: text: DeepSeek-V3 is supported by the  ... nd ZeRO-1 Data Parallelism (DP)[zero].
  item-100 at level 1: paragraph: In order to facilitate efficient training of
  item-101 at level 1: text: DeepSeek-V3, we implement meticu ... t using costly Tensor Parallelism(TP).
  item-102 at level 1: section_header: DualPipe and Computation-Communication Overlap
  item-103 at level 1: section: group figure
    item-104 at level 2: picture
      item-104 at level 3: caption: Image: figures/overlap.pdf
    item-105 at level 2: text: Overlapping strategy for a pair  ...  PP communication can be fully hidden.
  item-106 at level 1: caption: Image: figures/overlap.pdf
  item-107 at level 1: paragraph: For
  item-108 at level 1: text: DeepSeek-V3, the communication o ... but also reduces the pipeline bubbles.
  item-109 at level 1: paragraph: The key idea of DualPipe is to o ... ivide each chunk into four components:
  item-110 at level 1: text: attention, all-to-all dispatch,  ... ero all-to-all communication overhead.
  item-111 at level 1: section: group figure
    item-112 at level 2: picture
      item-112 at level 3: caption: Image: figures/dualpipe.pdf
    item-113 at level 2: text: Example DualPipe scheduling for  ... rlapped computation and communication.
  item-114 at level 1: caption: Image: figures/dualpipe.pdf
  item-115 at level 1: paragraph: In addition, even in more genera ... ibits efficiency advantages. 
In Table
  item-116 at level 1: text: [tab:dualpipe-bubble], we summar ...  as the number of micro-batches grows.
  item-117 at level 1: text: 15pt
  item-118 at level 1: table with [5x4]
  item-119 at level 1: text: Comparison of pipeline bubbles a ... verlapped forward and backward chunks.
  item-120 at level 1: section_header: Efficient Implementation of Cross-Node All-to-All Communication
  item-121 at level 1: paragraph: In order to ensure sufficient co ... om NVLink.
This implies that, although
  item-122 at level 1: text: DeepSeek-V3 selects only 8 route ... ilize the bandwidths of IB and NVLink.
  item-123 at level 1: paragraph: In detail, we employ the warp specialization technique
  item-124 at level 1: text: [warp-spec]and partition 20 SMs  ... che and the interference to other SMs.
  item-125 at level 1: section_header: Extremely Memory Saving with Minimal Overhead
  item-126 at level 1: paragraph: In order to reduce the memory fo ... g, we employ the following techniques.
  item-127 at level 1: text: Recomputation of RMSNorm and MLA Up-Projection.
  item-128 at level 1: paragraph: We recompute all RMSNorm operati ...  requirements for storing activations.
  item-129 at level 1: text: Exponential Moving Average in CP ... ng additional memory or time overhead.
  item-130 at level 1: text: Shared Embedding and Output Head ... urther enhances our memory efficiency.
  item-131 at level 1: section_header: FP8 Training
  item-132 at level 1: section: group figure
    item-133 at level 2: picture
      item-133 at level 3: caption: Image: figures/fp8-frameworkv3.pdf
    item-134 at level 2: text: The overall mixed precision fram ... ly the Linear operator is illustrated.
  item-135 at level 1: caption: Image: figures/fp8-frameworkv3.pdf
  item-136 at level 1: paragraph: Inspired by recent advances in low-precision training
  item-137 at level 1: text: [fp8lm, llm.int8, 8-bit-numerica ... ceptable range of training randomness.
  item-138 at level 1: section_header: Mixed Precision Framework
  item-139 at level 1: text: Building upon widely adopted tec ... ustrated in Figure[fig:fp8_framework].
  item-140 at level 1: paragraph: Firstly, in order to accelerate  ... n BF16 or FP32. 
As depicted in Figure
  item-141 at level 1: text: [fig:fp8_framework], all three G ... nificantly reduces memory consumption.
  item-142 at level 1: paragraph: Despite the efficiency advantage ... on ensure stable training dynamics for
  item-143 at level 1: text: DeepSeek-V3.
To further guarante ... ks in our distributed training system.
  item-144 at level 1: section: group figure
    item-145 at level 2: picture
      item-145 at level 3: caption: Image: figures/fp8-128accumulatorv4.pdf
    item-146 at level 2: text: (a) We propose a fine-grained qu ... A for the high-precision accumulation.
  item-147 at level 1: caption: Image: figures/fp8-128accumulatorv4.pdf
  item-148 at level 1: section_header: Improved Precision from Quantization and Multiplication
  item-149 at level 1: text: Based on our mixed precision FP8 ... method and the multiplication process.
  item-150 at level 1: text: Fine-Grained Quantization.
In lo ...  the same way as weights quantization.
  item-151 at level 1: paragraph: One key modification in our meth ... gy, it can be efficiently implemented.
  item-152 at level 1: paragraph: Notably, our fine-grained quanti ...  with the idea of microscaling formats
  item-153 at level 1: text: [rouhani2023microscaling], while ... ace with the latest GPU architectures.
  item-154 at level 1: text: Increasing Accumulation Precisio ... ly constraining the training accuracy.
  item-155 at level 1: paragraph: In order to address this issue,  ... ion to CUDA Cores for higher precision
  item-156 at level 1: text: [Thakkar_CUTLASS_2023]. 
The pro ... minimal additional computational cost.
  item-157 at level 1: paragraph: It is worth noting that this mod ... res.
Based on our experiments, setting
  item-158 at level 1: text: $N_C=128$elements, equivalent to ... hout introducing substantial overhead.
  item-159 at level 1: text: Mantissa over Exponents. 
In con ... e impact of the limited dynamic range.
  item-160 at level 1: text: Online Quantization.
Delayed qua ...  or weight online into the FP8 format.
  item-161 at level 1: section_header: Low-Precision Storage and Communication
  item-162 at level 1: text: In conjunction with our FP8 trai ... r states into lower-precision formats.
  item-163 at level 1: text: Low-Precision Optimizer States.
 ... merical stability throughout training.
  item-164 at level 1: text: Low-Precision Activation.
As ill ...  for low-cost high-precision training:
  item-165 at level 1: text: (1) Inputs of the Linear after t ... und scaled, i.e., integral power of 2.
  item-166 at level 1: text: (2) Inputs of the SwiGLU operato ... efficiency and computational accuracy.
  item-167 at level 1: text: Low-Precision Communication.
Com ... itical parts of the training pipeline.
  item-168 at level 1: section_header: Inference and Deployment
  item-169 at level 1: paragraph: We deploy
  item-170 at level 1: text: DeepSeek-V3 on the H800 cluster, ... tes the prefilling and decodingstages.
  item-171 at level 1: section_header: Prefilling
  item-172 at level 1: paragraph: The minimum deployment unit of t ... consists of 4 nodes with 32 GPUs. 
The
  item-173 at level 1: text: attention part employs 4-way Ten ... allow layers to save TP communication.
  item-174 at level 1: paragraph: To achieve load balancing among different experts in the
  item-175 at level 1: text: MoE part, we need to ensure that ...  host one additional redundant expert.
  item-176 at level 1: paragraph: Furthermore, in the prefilling s ... mputational workloads, overlapping the
  item-177 at level 1: text: attention and MoE of one micro-b ... th the dispatch and combineof another.
  item-178 at level 1: paragraph: Finally, we are exploring a
  item-179 at level 1: text: dynamic redundancystrategy for e ... s routing scheme is almost negligible.
  item-180 at level 1: section_header: Decoding
  item-181 at level 1: paragraph: During decoding, we treat the sh ... nsists of 40 nodes with 320 GPUs. 
The
  item-182 at level 1: text: attention part employs TP4 with  ...  and enhance communication efficiency.
  item-183 at level 1: paragraph: Similar to prefilling, we period ... one expert. 
We are also exploring the
  item-184 at level 1: text: dynamic redundancy strategy for  ... the dispatchkernel to reduce overhead.
  item-185 at level 1: paragraph: Additionally, to enhance through ... he decoding stage. 
Unlike prefilling,
  item-186 at level 1: text: attention consumes a larger port ... ortion of SMs to dispatch+MoE+combine.
  item-187 at level 1: section_header: Suggestions on Hardware Design
  item-188 at level 1: paragraph: Based on our implementation of t ... on chip design to AI hardware vendors.
  item-189 at level 1: section_header: Communication Hardware
  item-190 at level 1: paragraph: In
  item-191 at level 1: text: DeepSeek-V3, we implement the ov ...  cores remain entirely under-utilized.
  item-192 at level 1: paragraph: Currently, the SMs primarily per ... ng tasks for all-to-all communication:
  item-193 at level 1: list: group list
    item-194 at level 2: list_item: Forwarding data between the IB ( ... ithin the same node from a single GPU.
    item-195 at level 2: list_item: Transporting data between RDMA b ... ory regions) and input/output buffers.
    item-196 at level 2: list_item: Executing reduce operations for all-to-all combine.
    item-197 at level 2: list_item: Managing fine-grained memory lay ... perts across the IB and NVLink domain.
  item-198 at level 1: paragraph: We aspire to see future vendors  ... network co-processor like NVIDIA SHARP
  item-199 at level 1: text: [nvsharp]. 
Furthermore, to redu ... n requests based on simple primitives.
  item-200 at level 1: section_header: Compute Hardware
  item-201 at level 1: text: Higher FP8 GEMM Accumulation Pre ...  chips need to adopt higher precision.
  item-202 at level 1: text: Support for Tile- and Block-Wise ... ced, avoiding frequent data movements.
  item-203 at level 1: text: Support for Online Quantization. ... off-chip memory access by roughly 50%.
  item-204 at level 1: text: Support for Transposed GEMM Oper ...  streamline the quantization workflow.
  item-205 at level 1: section_header: Pre-Training
  item-206 at level 1: section_header: Data Construction
  item-207 at level 1: paragraph: Compared with
  item-208 at level 1: text: DeepSeek-V2, we optimize the pre ... y and diverse tokens in our tokenizer.
  item-209 at level 1: paragraph: In the training process of DeepSeekCoder-V2
  item-210 at level 1: text: [dscodervii], we observe that th ... ramework to structure data as follows:
  item-211 at level 1: formula: \begin{align}
\texttt{<|fim\_beg ... |eos\_token|>} . \nonumber
\end{align}
  item-212 at level 1: text: This structure is applied at the ... .1, consistent with the PSM framework.
  item-213 at level 1: paragraph: The tokenizer for
  item-214 at level 1: text: DeepSeek-V3 employs Byte-level B ... special cases and mitigates this bias.
  item-215 at level 1: section_header: Hyper-Parameters
  item-216 at level 1: text: Model Hyper-Parameters.
We set t ... hich 37B are activated for each token.
  item-217 at level 1: text: Training Hyper-Parameters.
We em ...  to 0.1 for the remaining 4.8T tokens.
  item-218 at level 1: section: group figure
    item-219 at level 2: picture
      item-219 at level 3: caption: Image: figures/needle_in_a_haystack.pdf
    item-220 at level 2: text: Evaluation results on the Needle ... all context window lengths up to 128K.
  item-221 at level 1: caption: Image: figures/needle_in_a_haystack.pdf
  item-222 at level 1: section_header: Long Context Extension
  item-223 at level 1: paragraph: We adopt a similar approach to
  item-224 at level 1: text: DeepSeek-V2[dsvii] to enable lon ... ning rate from the pre-training stage.
  item-225 at level 1: paragraph: Through this two-phase extension training,
  item-226 at level 1: text: DeepSeek-V3 is capable of handli ... oss context window lengths up to 128K.
  item-227 at level 1: section_header: Evaluations
  item-228 at level 1: section_header: Evaluation Benchmarks
  item-229 at level 1: paragraph: The base model of
  item-230 at level 1: text: DeepSeek-V3 is pretrained on a m ... linedbenchmarks are multilingual ones:
  item-231 at level 1: text: Multi-subject multiple-choice da ... u], C-Eval [ceval], and CMMLU [cmmlu].
  item-232 at level 1: text: Language understanding and reaso ...  [arc], and BigBench Hard (BBH) [bbh].
  item-233 at level 1: text: Closed-book question answering d ... d NaturalQuestions [naturalquestions].
  item-234 at level 1: text: Reading comprehension datasets i ... ating], and CMRC [cui-etal-2019-span].
  item-235 at level 1: text: Reference disambiguation dataset ...  WinoGrande [sakaguchi2019winogrande].
  item-236 at level 1: text: Language modeling datasets include Pile [pile].
  item-237 at level 1: text: Chinese understanding and culture datasets include CCPM [li2021ccpm].
  item-238 at level 1: text: Math datasets include GSM8K[gsm8 ... MGSM [mgsm], and CMath [wei2023cmath].
  item-239 at level 1: text: Code datasets include HumanEval[ ... P[mbpp], and CRUXEval[gu2024cruxeval].
  item-240 at level 1: text: Standardized exams include AGIEv ... udes both English and Chinese subsets.
  item-241 at level 1: text: Following our previous work[dsvi ... ong models using different tokenizers.
  item-242 at level 1: text: 4.5pt
  item-243 at level 1: table with [38x9]
  item-244 at level 1: text: Comparison among DeepSeek-V3-Bas ... ks, especially on math and code tasks.
  item-245 at level 1: section_header: Evaluation Results
  item-246 at level 1: paragraph: In Table
  item-247 at level 1: text: [tab:main], we compare the base  ... oming the strongest open-source model.
  item-248 at level 1: paragraph: From a more detailed perspective, we compare
  item-249 at level 1: text: DeepSeek-V3-Base with the other  ... series, DROP, C-Eval, CMMLU, and CCPM.
  item-250 at level 1: paragraph: Due to our efficient architectur ... mprehensive engineering optimizations,
  item-251 at level 1: text: DeepSeek-V3 achieves extremely h ... han training 72B or 405B dense models.
  item-252 at level 1: text: 8pt
  item-253 at level 1: table with [16x6]
  item-254 at level 1: text: Ablation results for the MTP str ...  on most of the evaluation benchmarks.
  item-255 at level 1: section_header: Discussion
  item-256 at level 1: section_header: Ablation Studies for Multi-Token Prediction
  item-257 at level 1: paragraph: In Table
  item-258 at level 1: text: [tab:ablation_nextn], we show th ...  on most of the evaluation benchmarks.
  item-259 at level 1: section_header: Ablation Studies for the Auxiliary-Loss-Free Balancing Strategy
  item-260 at level 1: paragraph: In Table
  item-261 at level 1: text: [tab:ablation_noaux_tc], we show ...  on most of the evaluation benchmarks.
  item-262 at level 1: text: 4pt
  item-263 at level 1: table with [16x6]
  item-264 at level 1: text: Ablation results for the auxilia ...  on most of the evaluation benchmarks.
  item-265 at level 1: section_header: Batch-Wise Load Balance VS. Sequence-Wise Load Balance
  item-266 at level 1: paragraph: The key distinction between auxi ... ile test set.
As illustrated in Figure
  item-267 at level 1: text: [fig:expert_load], we observe th ... t specialization patterns as expected.
  item-268 at level 1: paragraph: To further investigate the corre ... eve the same validation loss of 2.080.
  item-269 at level 1: paragraph: In addition, although the batch- ... rt deployment, as described in Section
  item-270 at level 1: text: [sec:inference_deployment], to overcome it.
  item-271 at level 1: section: group figure
    item-272 at level 2: picture
      item-272 at level 3: caption: Image: figures/relative_expert_load_multi.pdf
    item-273 at level 2: text: Expert load of auxiliary-loss-fr ... ppendix\ref{app:detailed_expert_load}.
  item-274 at level 1: caption: Image: figures/relative_expert_load_multi.pdf
  item-275 at level 1: section_header: Post-Training
  item-276 at level 1: section_header: Supervised Fine-Tuning
  item-277 at level 1: paragraph: We curate our instruction-tuning ... tailored to its specific requirements.
  item-278 at level 1: text: Reasoning Data.For reasoning-rel ... of regularly formatted reasoning data.
  item-279 at level 1: paragraph: To establish our methodology, we ... <system prompt, problem, R1 response>.
  item-280 at level 1: paragraph: The system prompt is meticulousl ... ing overall performance strategically.
  item-281 at level 1: paragraph: Upon completing the RL training  ... ponses that are concise and effective.
  item-282 at level 1: text: Non-Reasoning Data.For non-reaso ...  accuracy and correctness of the data.
  item-283 at level 1: text: SFT Settings. 
We fine-tune Deep ... emain isolated and mutually invisible.
  item-284 at level 1: section_header: Reinforcement Learning
  item-285 at level 1: section_header: Reward Model
  item-286 at level 1: paragraph: We employ a rule-based Reward Mo ... nd a model-based RM in our RL process.
  item-287 at level 1: text: Rule-Based RM.For questions that ... stant to manipulation or exploitation.
  item-288 at level 1: text: Model-Based RM. 
For questions w ... k of reward hacking in specific tasks.
  item-289 at level 1: section_header: Group Relative Policy Optimization
  item-290 at level 1: paragraph: Similar to
  item-291 at level 1: text: DeepSeek-V2[dsvii], we adopt Gro ... by maximizing the following objective:
  item-292 at level 1: formula: \begin{split}
    \mathcal{J}_{G ...  \pi_{ref}\right)\right) ,
\end{split}
  item-293 at level 1: formula: \mathbb{D}_{KL}\left(\pi_{\theta ... ref}(o_i|q)}{\pi_{\theta}(o_i|q)} - 1,
  item-294 at level 1: text: where $\epsilon$ and $\beta$ are ... ding to the outputs within each group:
  item-295 at level 1: formula: A_i = \frac{r_i - {\operatorname ... ame{std}(\{r_1, r_2, \cdots, r_G\})}}.
  item-296 at level 1: paragraph: We incorporate prompts from dive ...  where available SFT data are limited.
  item-297 at level 1: section_header: Evaluations
  item-298 at level 1: section_header: Evaluation Settings
  item-299 at level 1: text: Evaluation Benchmarks.
Apart fro ... WE-Bench Verified[swe_verified], Aider
  item-300 at level 1: footnote: https://aider.chat
  item-301 at level 1: text: , LiveCodeBench[livecodebench] ( ... ust 2024 to November 2024), Codeforces
  item-302 at level 1: footnote: https://codeforces.com
  item-303 at level 1: text: , Chinese National High School Mathematics Olympiad (CNMO 2024)
  item-304 at level 1: footnote: https://www.cms.org.cn/Home/comp/comp/cid/12.html
  item-305 at level 1: text: , and American Invitational Math ... xamination 2024 (AIME 2024)[AIME2024].
  item-306 at level 1: text: Compared Baselines.
We conduct c ... rformed through their respective APIs.
  item-307 at level 1: text: Detailed Evaluation Configuratio ... rompts from the simple-evals framework
  item-308 at level 1: footnote: https://github.com/openai/simple-evals
  item-309 at level 1: text: . 
We utilize the Zero-Eval prom ... mum of 8192 tokens for each benchmark.
  item-310 at level 1: text: 1.9pt
  item-311 at level 1: table with [28x10]
  item-312 at level 1: text: Comparison between DeepSeek-V3 a ... against frontier closed-source models.
  item-313 at level 1: section_header: Standard Evaluation
  item-314 at level 1: paragraph: Table
  item-315 at level 1: text: [tab:chat] presents the evaluati ... els like GPT-4o and Claude-3.5-Sonnet.
  item-316 at level 1: text: English Benchmarks.
MMLU is a wi ... r competitors by a substantial margin.
  item-317 at level 1: paragraph: In long-context understanding be ... uch as DROP, LongBench v2, and FRAMES,
  item-318 at level 1: text: DeepSeek-V3 continues to demonst ... re to user-defined format constraints.
  item-319 at level 1: text: Code and Math Benchmarks.
Coding ... pabilities in algorithm-focused tasks.
  item-320 at level 1: paragraph: On math benchmarks,
  item-321 at level 1: text: DeepSeek-V3 demonstrates excepti ... hly beneficial for non-o1-like models.
  item-322 at level 1: text: Chinese Benchmarks.
Qwen and Dee ... ens that DeepSeek-V3is pre-trained on.
  item-323 at level 1: paragraph: On C-Eval, a representative benc ... C (Chinese Winograd Schema Challenge),
  item-324 at level 1: text: DeepSeek-V3and Qwen2.5-72B exhib ... guage reasoning and educational tasks.
  item-325 at level 1: table with [8x3]
  item-326 at level 1: text: English open-ended conversation  ... gth-controlled win rate as the metric.
  item-327 at level 1: section_header: Open-Ended Evaluation
  item-328 at level 1: paragraph: In addition to standard benchmar ... udges, with the results shown in Table
  item-329 at level 1: text: [tab:open]. 
Specifically, we ad ... can accomplish in challenging domains.
  item-330 at level 1: paragraph: Similarly,
  item-331 at level 1: text: DeepSeek-V3 showcases exceptiona ... the effectiveness of its advancements.
  item-332 at level 1: section_header: DeepSeek-V3 as a Generative Reward Model
  item-333 at level 1: paragraph: We compare the judgment ability of
  item-334 at level 1: text: DeepSeek-V3 with state-of-the-ar ... d robustness of the alignment process.
  item-335 at level 1: table with [9x6]
  item-336 at level 1: text: Performances of GPT-4o, Claude-3.5-sonnet and DeepSeek-V3 on RewardBench.
  item-337 at level 1: section_header: Discussion
  item-338 at level 1: section_header: Distillation from DeepSeek-R1
  item-339 at level 1: paragraph: We ablate the contribution of di ... he expert checkpoints described above.
  item-340 at level 1: paragraph: Table
  item-341 at level 1: text: [tab:distill] demonstrates the e ... ttings for DeepSeek-V3in distillation.
  item-342 at level 1: paragraph: Our research suggests that knowl ... portant direction for future research.
  item-343 at level 1: table with [5x5]
  item-344 at level 1: text: The contribution of distillation ... re the same as in Table\ref{tab:chat}.
  item-345 at level 1: section_header: Self-Rewarding
  item-346 at level 1: paragraph: Rewards play a pivotal role in R ... mpractical. 
During the development of
  item-347 at level 1: text: DeepSeek-V3, for these broader c ... del capabilities in general scenarios.
  item-348 at level 1: section_header: Multi-Token Prediction Evaluation
  item-349 at level 1: paragraph: Instead of predicting just the next single token,
  item-350 at level 1: text: DeepSeek-V3 predicts the next 2  ... ing 1.8 times TPS (Tokens Per Second).
  item-351 at level 1: section_header: Conclusion, Limitations, and Future Directions
  item-352 at level 1: paragraph: In this paper, we introduce
  item-353 at level 1: text: DeepSeek-V3, a large MoE languag ... t length extension, and post-training.
  item-354 at level 1: paragraph: While acknowledging its strong p ... -effectiveness, we also recognize that
  item-355 at level 1: text: DeepSeek-V3 has some limitations ... development of more advanced hardware.
  item-356 at level 1: paragraph: DeepSeek consistently adheres to ... earch across the following directions.
  item-357 at level 1: list: group list
    item-358 at level 2: list_item: We will consistently study and r ... undaries of its modeling capabilities.
    item-359 at level 2: list_item: We will continuously iterate on  ... ore comprehensive range of dimensions.
    item-360 at level 2: list_item: We will consistently explore and ... ding their reasoning length and depth.
    item-361 at level 2: list_item: We will explore more comprehensi ... nd affect our foundational assessment.
  item-362 at level 1: text: main
  item-363 at level 1: section_header: Appendix
  item-364 at level 1: section_header: Contributions and Acknowledgments
  item-365 at level 1: text: 2 damaiblue Research & Engineeri ... 
 Ziyang Song 
 Ziyi Gao 
 Zizheng Pan
  item-366 at level 1: text: damaigreen Data Annotation 
 Bei ... hen Huang 
 Zhipeng Xu 
 Zhongyu Zhang
  item-367 at level 1: text: damaired Business & Compliance 
 ...  
 Yukun Zha 
 Yuting Yan 
 Zhen Zhang
  item-368 at level 1: paragraph: Within each role, authors are li ... duals who have departed from our team.
  item-369 at level 1: section_header: Ablation Studies for Low-Precision Training
  item-370 at level 1: section: group figure
    item-371 at level 2: picture
      item-371 at level 3: caption: Image: figures/fp8-v.s.-bf16.pdf
    item-372 at level 2: text: Loss curves comparison between B ... erage (EMA) with a coefficient of 0.9.
  item-373 at level 1: caption: Image: figures/fp8-v.s.-bf16.pdf
  item-374 at level 1: section_header: FP8 v.s. BF16 Training
  item-375 at level 1: text: We validate our FP8 mixed precis ...  fine-grained quantization strategies.
  item-376 at level 1: section_header: Discussion About Block-Wise Quantization
  item-377 at level 1: text: Although our tile-wise fine-grai ... by a block-wise quantization approach.
  item-378 at level 1: section_header: Expert Specialization Patterns o ... ux-Loss-Based and Aux-Loss-Free Models
  item-379 at level 1: text: We record the expert load of the ... d in Figure[fig:detailed_expert_load].
  item-380 at level 1: section: group figure
    item-381 at level 2: text: [Layers 1-7]
    item-382 at level 2: picture
      item-382 at level 3: caption: Image: figures/relative_expert_load_multi_1-6.pdf
  item-383 at level 1: caption: Image: figures/relative_expert_load_multi_1-6.pdf
  item-384 at level 1: section: group figure
    item-385 at level 2: text: [Layers 7-13]
    item-386 at level 2: picture
      item-386 at level 3: caption: Image: figures/relative_expert_load_multi_7-12.pdf
  item-387 at level 1: caption: Image: figures/relative_expert_load_multi_7-12.pdf
  item-388 at level 1: section: group figure
    item-389 at level 2: text: [Layers 13-19]
    item-390 at level 2: picture
      item-390 at level 3: caption: Image: figures/relative_expert_load_multi_13-18.pdf
  item-391 at level 1: caption: Image: figures/relative_expert_load_multi_13-18.pdf
  item-392 at level 1: section: group figure
    item-393 at level 2: text: [Layers 19-25]
    item-394 at level 2: picture
      item-394 at level 3: caption: Image: figures/relative_expert_load_multi_19-24.pdf
  item-395 at level 1: caption: Image: figures/relative_expert_load_multi_19-24.pdf
  item-396 at level 1: section: group figure
    item-397 at level 2: text: [Layers 25-27]
    item-398 at level 2: picture
      item-398 at level 3: caption: Image: figures/relative_expert_load_multi_25-26.pdf
    item-399 at level 2: text: Expert load of auxiliary-loss-fr ... he theoretically balanced expert load.
  item-400 at level 1: caption: Image: figures/relative_expert_load_multi_25-26.pdf