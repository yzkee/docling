{
  "schema_name": "DoclingDocument",
  "version": "1.8.0",
  "name": "deepseek_title",
  "origin": {
    "mimetype": "text/markdown",
    "binary_hash": 0,
    "filename": "deepseek_title.md"
  },
  "furniture": {
    "self_ref": "#/furniture",
    "children": [],
    "content_layer": "furniture",
    "name": "_root_",
    "label": "unspecified"
  },
  "body": {
    "self_ref": "#/body",
    "children": [
      {
        "$ref": "#/texts/0"
      },
      {
        "$ref": "#/texts/1"
      },
      {
        "$ref": "#/texts/2"
      },
      {
        "$ref": "#/texts/3"
      },
      {
        "$ref": "#/texts/4"
      },
      {
        "$ref": "#/texts/5"
      },
      {
        "$ref": "#/texts/6"
      },
      {
        "$ref": "#/texts/7"
      },
      {
        "$ref": "#/texts/8"
      },
      {
        "$ref": "#/texts/9"
      },
      {
        "$ref": "#/texts/10"
      },
      {
        "$ref": "#/pictures/0"
      },
      {
        "$ref": "#/texts/11"
      },
      {
        "$ref": "#/texts/12"
      },
      {
        "$ref": "#/texts/13"
      },
      {
        "$ref": "#/texts/14"
      }
    ],
    "content_layer": "body",
    "name": "_root_",
    "label": "unspecified"
  },
  "groups": [],
  "texts": [
    {
      "self_ref": "#/texts/0",
      "parent": {
        "$ref": "#/body"
      },
      "children": [],
      "content_layer": "body",
      "label": "title",
      "prov": [
        {
          "page_no": 1,
          "bbox": {
            "l": 104.65,
            "t": 79.99,
            "r": 504.9,
            "b": 118.8,
            "coord_origin": "TOPLEFT"
          },
          "charspan": [
            0,
            0
          ]
        }
      ],
      "orig": "DocLayNet: A Large Human-Annotated Dataset for Document-Layout Analysis",
      "text": "DocLayNet: A Large Human-Annotated Dataset for Document-Layout Analysis"
    },
    {
      "self_ref": "#/texts/1",
      "parent": {
        "$ref": "#/body"
      },
      "children": [],
      "content_layer": "body",
      "label": "text",
      "prov": [
        {
          "page_no": 1,
          "bbox": {
            "l": 87.52,
            "t": 129.89,
            "r": 190.33,
            "b": 179.78,
            "coord_origin": "TOPLEFT"
          },
          "charspan": [
            0,
            0
          ]
        }
      ],
      "orig": "Birgit Pfitzmann IBM Research Rueschlikon, Switzerland bpf@zurich.ibm.com",
      "text": "Birgit Pfitzmann IBM Research Rueschlikon, Switzerland bpf@zurich.ibm.com"
    },
    {
      "self_ref": "#/texts/2",
      "parent": {
        "$ref": "#/body"
      },
      "children": [],
      "content_layer": "body",
      "label": "text",
      "prov": [
        {
          "page_no": 1,
          "bbox": {
            "l": 252.14,
            "t": 129.89,
            "r": 358.02,
            "b": 179.78,
            "coord_origin": "TOPLEFT"
          },
          "charspan": [
            0,
            0
          ]
        }
      ],
      "orig": "Christoph Auer IBM Research Rueschlikon, Switzerland cau@zurich.ibm.com",
      "text": "Christoph Auer IBM Research Rueschlikon, Switzerland cau@zurich.ibm.com"
    },
    {
      "self_ref": "#/texts/3",
      "parent": {
        "$ref": "#/body"
      },
      "children": [],
      "content_layer": "body",
      "label": "text",
      "prov": [
        {
          "page_no": 1,
          "bbox": {
            "l": 416.16,
            "t": 129.89,
            "r": 522.04,
            "b": 179.78,
            "coord_origin": "TOPLEFT"
          },
          "charspan": [
            0,
            0
          ]
        }
      ],
      "orig": "Michele Dolfi IBM Research Rueschlikon, Switzerland dol@zurich.ibm.com",
      "text": "Michele Dolfi IBM Research Rueschlikon, Switzerland dol@zurich.ibm.com"
    },
    {
      "self_ref": "#/texts/4",
      "parent": {
        "$ref": "#/body"
      },
      "children": [],
      "content_layer": "body",
      "label": "text",
      "prov": [
        {
          "page_no": 1,
          "bbox": {
            "l": 169.52,
            "t": 188.5,
            "r": 275.4,
            "b": 237.6,
            "coord_origin": "TOPLEFT"
          },
          "charspan": [
            0,
            0
          ]
        }
      ],
      "orig": "Ahmed S. Nassar IBM Research Rueschlikon, Switzerland ahn@zurich.ibm.com",
      "text": "Ahmed S. Nassar IBM Research Rueschlikon, Switzerland ahn@zurich.ibm.com"
    },
    {
      "self_ref": "#/texts/5",
      "parent": {
        "$ref": "#/body"
      },
      "children": [],
      "content_layer": "body",
      "label": "text",
      "prov": [
        {
          "page_no": 1,
          "bbox": {
            "l": 333.54,
            "t": 188.5,
            "r": 438.8,
            "b": 237.6,
            "coord_origin": "TOPLEFT"
          },
          "charspan": [
            0,
            0
          ]
        }
      ],
      "orig": "Peter Staar IBM Research Rueschlikon, Switzerland taa@zurich.ibm.com",
      "text": "Peter Staar IBM Research Rueschlikon, Switzerland taa@zurich.ibm.com"
    },
    {
      "self_ref": "#/texts/6",
      "parent": {
        "$ref": "#/body"
      },
      "children": [],
      "content_layer": "body",
      "label": "section_header",
      "prov": [
        {
          "page_no": 1,
          "bbox": {
            "l": 52.63,
            "t": 245.52,
            "r": 111.38,
            "b": 256.61,
            "coord_origin": "TOPLEFT"
          },
          "charspan": [
            0,
            0
          ]
        }
      ],
      "orig": "ABSTRACT",
      "text": "ABSTRACT",
      "level": 1
    },
    {
      "self_ref": "#/texts/7",
      "parent": {
        "$ref": "#/body"
      },
      "children": [],
      "content_layer": "body",
      "label": "text",
      "prov": [
        {
          "page_no": 1,
          "bbox": {
            "l": 52.02,
            "t": 260.57,
            "r": 294.37,
            "b": 533.81,
            "coord_origin": "TOPLEFT"
          },
          "charspan": [
            0,
            0
          ]
        }
      ],
      "orig": "Accurate document layout analysis is a key requirement for high- quality PDF document conversion. With the recent availability of public, large ground- truth datasets such as PubLayNet and DocBank, deep- learning models have proven to be very effective at layout detection and segmentation. While these datasets are of adequate size to train such models, they severely lack in layout variability since they are sourced from scientific article repositories such as PubMed and arXiv only. Consequently, the accuracy of the layout segmentation drops significantly when these models are applied on more challenging and diverse layouts. In this paper, we present DocLayNet, a new, publicly available, document- layout annotation dataset in COCO format. It contains 80863 manually annotated pages from diverse data sources to represent a wide variability in layouts. For each PDF page, the layout annotations provide labelled bounding- boxes with a choice of 11 distinct classes. DocLayNet also provides a subset of double- and triple- annotated pages to determine the inter- annotator agreement. In multiple experiments, we provide baseline accuracy scores (in mAP) for a set of popular object detection models. We also demonstrate that these models fall approximately \\(10\\%\\) behind the inter- annotator agreement. Furthermore, we provide evidence that DocLayNet is of sufficient size. Lastly, we compare models trained on PubLayNet, DocBank and DocLayNet, showing that layout predictions of the DocLayNet- trained models are more robust and thus the preferred choice for general- purpose document- layout analysis.",
      "text": "Accurate document layout analysis is a key requirement for high- quality PDF document conversion. With the recent availability of public, large ground- truth datasets such as PubLayNet and DocBank, deep- learning models have proven to be very effective at layout detection and segmentation. While these datasets are of adequate size to train such models, they severely lack in layout variability since they are sourced from scientific article repositories such as PubMed and arXiv only. Consequently, the accuracy of the layout segmentation drops significantly when these models are applied on more challenging and diverse layouts. In this paper, we present DocLayNet, a new, publicly available, document- layout annotation dataset in COCO format. It contains 80863 manually annotated pages from diverse data sources to represent a wide variability in layouts. For each PDF page, the layout annotations provide labelled bounding- boxes with a choice of 11 distinct classes. DocLayNet also provides a subset of double- and triple- annotated pages to determine the inter- annotator agreement. In multiple experiments, we provide baseline accuracy scores (in mAP) for a set of popular object detection models. We also demonstrate that these models fall approximately \\(10\\%\\) behind the inter- annotator agreement. Furthermore, we provide evidence that DocLayNet is of sufficient size. Lastly, we compare models trained on PubLayNet, DocBank and DocLayNet, showing that layout predictions of the DocLayNet- trained models are more robust and thus the preferred choice for general- purpose document- layout analysis."
    },
    {
      "self_ref": "#/texts/8",
      "parent": {
        "$ref": "#/body"
      },
      "children": [],
      "content_layer": "body",
      "label": "section_header",
      "prov": [
        {
          "page_no": 1,
          "bbox": {
            "l": 52.63,
            "t": 548.06,
            "r": 134.64,
            "b": 559.94,
            "coord_origin": "TOPLEFT"
          },
          "charspan": [
            0,
            0
          ]
        }
      ],
      "orig": "CCS CONCEPTS",
      "text": "CCS CONCEPTS",
      "level": 1
    },
    {
      "self_ref": "#/texts/9",
      "parent": {
        "$ref": "#/body"
      },
      "children": [],
      "content_layer": "body",
      "label": "text",
      "prov": [
        {
          "page_no": 1,
          "bbox": {
            "l": 52.63,
            "t": 563.11,
            "r": 294.37,
            "b": 596.38,
            "coord_origin": "TOPLEFT"
          },
          "charspan": [
            0,
            0
          ]
        }
      ],
      "orig": "- Information systems \\(\\rightarrow\\) Document structure; \\(\\cdot\\) Applied computing \\(\\rightarrow\\) Document analysis; \\(\\cdot\\) Computing methodologies \\(\\rightarrow\\) Machine learning; Computer vision; Object detection;",
      "text": "- Information systems \\(\\rightarrow\\) Document structure; \\(\\cdot\\) Applied computing \\(\\rightarrow\\) Document analysis; \\(\\cdot\\) Computing methodologies \\(\\rightarrow\\) Machine learning; Computer vision; Object detection;"
    },
    {
      "self_ref": "#/texts/10",
      "parent": {
        "$ref": "#/body"
      },
      "children": [],
      "content_layer": "body",
      "label": "caption",
      "prov": [
        {
          "page_no": 1,
          "bbox": {
            "l": 315.18,
            "t": 536.18,
            "r": 558.14,
            "b": 557.57,
            "coord_origin": "TOPLEFT"
          },
          "charspan": [
            0,
            0
          ]
        }
      ],
      "orig": "<center>Figure 1: Four examples of complex page layouts across different document categories </center>",
      "text": "<center>Figure 1: Four examples of complex page layouts across different document categories </center>"
    },
    {
      "self_ref": "#/texts/11",
      "parent": {
        "$ref": "#/body"
      },
      "children": [],
      "content_layer": "body",
      "label": "section_header",
      "prov": [
        {
          "page_no": 1,
          "bbox": {
            "l": 316.4,
            "t": 587.66,
            "r": 378.83,
            "b": 599.54,
            "coord_origin": "TOPLEFT"
          },
          "charspan": [
            0,
            0
          ]
        }
      ],
      "orig": "KEYWORDS",
      "text": "KEYWORDS",
      "level": 1
    },
    {
      "self_ref": "#/texts/12",
      "parent": {
        "$ref": "#/body"
      },
      "children": [],
      "content_layer": "body",
      "label": "text",
      "prov": [
        {
          "page_no": 1,
          "bbox": {
            "l": 316.4,
            "t": 602.71,
            "r": 558.14,
            "b": 624.89,
            "coord_origin": "TOPLEFT"
          },
          "charspan": [
            0,
            0
          ]
        }
      ],
      "orig": "PDF document conversion, layout segmentation, object- detection, data set, Machine Learning",
      "text": "PDF document conversion, layout segmentation, object- detection, data set, Machine Learning"
    },
    {
      "self_ref": "#/texts/13",
      "parent": {
        "$ref": "#/body"
      },
      "children": [],
      "content_layer": "body",
      "label": "section_header",
      "prov": [
        {
          "page_no": 1,
          "bbox": {
            "l": 316.4,
            "t": 636.77,
            "r": 403.92,
            "b": 645.48,
            "coord_origin": "TOPLEFT"
          },
          "charspan": [
            0,
            0
          ]
        }
      ],
      "orig": "ACM Reference Format:",
      "text": "ACM Reference Format:",
      "level": 1
    },
    {
      "self_ref": "#/texts/14",
      "parent": {
        "$ref": "#/body"
      },
      "children": [],
      "content_layer": "body",
      "label": "text",
      "prov": [
        {
          "page_no": 1,
          "bbox": {
            "l": 316.4,
            "t": 646.27,
            "r": 558.14,
            "b": 707.26,
            "coord_origin": "TOPLEFT"
          },
          "charspan": [
            0,
            0
          ]
        }
      ],
      "orig": "Birgit Pfitzmann, Christoph Auer, Michele Dolfi, Ahmed S. Nassar, and Peter Staar. 2022. DocLayNet: A Large Human- Annotated Dataset for Document- Layout Analysis. In Proceedings of the 28th ACM SIGKDD Conference on Knowledge Discovery and Data Mining (KDD '22), August 14- 18, 2022, Washington, DC, USA. ACM, New York, NY, USA, 9 pages. https://doi.org/10.1145/3534678.3539043",
      "text": "Birgit Pfitzmann, Christoph Auer, Michele Dolfi, Ahmed S. Nassar, and Peter Staar. 2022. DocLayNet: A Large Human- Annotated Dataset for Document- Layout Analysis. In Proceedings of the 28th ACM SIGKDD Conference on Knowledge Discovery and Data Mining (KDD '22), August 14- 18, 2022, Washington, DC, USA. ACM, New York, NY, USA, 9 pages. https://doi.org/10.1145/3534678.3539043"
    }
  ],
  "pictures": [
    {
      "self_ref": "#/pictures/0",
      "parent": {
        "$ref": "#/body"
      },
      "children": [],
      "content_layer": "body",
      "label": "picture",
      "prov": [
        {
          "page_no": 1,
          "bbox": {
            "l": 324.36,
            "t": 245.52,
            "r": 553.86,
            "b": 527.47,
            "coord_origin": "TOPLEFT"
          },
          "charspan": [
            0,
            0
          ]
        }
      ],
      "captions": [
        {
          "$ref": "#/texts/10"
        }
      ],
      "references": [],
      "footnotes": [],
      "annotations": []
    }
  ],
  "tables": [],
  "key_value_items": [],
  "form_items": [],
  "pages": {
    "1": {
      "size": {
        "width": 612.0,
        "height": 792.0
      },
      "image": {
        "mimetype": "image/png",
        "dpi": 72,
        "size": {
          "width": 612.0,
          "height": 792.0
        },
        "uri": "data:image/png;base64,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"
      },
      "page_no": 1
    }
  }
}